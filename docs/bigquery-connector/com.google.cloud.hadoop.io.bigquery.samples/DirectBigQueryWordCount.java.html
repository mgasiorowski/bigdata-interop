<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>DirectBigQueryWordCount.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">coverage</a> &gt; <a href="../index.html" class="el_bundle">bigquery-connector</a> &gt; <a href="index.source.html" class="el_package">com.google.cloud.hadoop.io.bigquery.samples</a> &gt; <span class="el_source">DirectBigQueryWordCount.java</span></div><h1>DirectBigQueryWordCount.java</h1><pre class="source lang-java linenums">/*
 * Copyright 2019 Google LLC
 *
 *  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software distributed under the
 * License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.google.cloud.hadoop.io.bigquery.samples;

import com.google.cloud.hadoop.io.bigquery.BigQueryConfiguration;
import com.google.cloud.hadoop.io.bigquery.DirectBigQueryInputFormat;
import java.io.IOException;
import java.util.stream.StreamSupport;
import org.apache.avro.generic.GenericRecord;
import org.apache.avro.util.Utf8;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.MRJobConfig;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * An example Hadoop WordCount program that counts the number of times a word appears in a BigQuery
 * table column.
 */
<span class="nc" id="L41">public class DirectBigQueryWordCount {</span>
<span class="nc" id="L42">  private static final Logger log = LoggerFactory.getLogger(DirectBigQueryWordCount.class);</span>

  /** The mapper for our WordCount job. */
<span class="nc" id="L45">  public static class Map extends Mapper&lt;NullWritable, GenericRecord, Text, LongWritable&gt; {</span>
<span class="nc" id="L46">    private final Text word = new Text();</span>
<span class="nc" id="L47">    private final LongWritable count = new LongWritable();</span>

    @Override
<span class="nc" id="L50">    public void setup(Context context) throws IOException, InterruptedException {}</span>

    @Override
    public void map(NullWritable unusedKey, GenericRecord row, Context context)
        throws IOException, InterruptedException {
<span class="nc" id="L55">      word.set(((Utf8) row.get(&quot;word&quot;)).toString());</span>
<span class="nc" id="L56">      count.set((Long) row.get(&quot;word_count&quot;));</span>
<span class="nc" id="L57">      context.write(word, count);</span>
<span class="nc" id="L58">    }</span>
  }

  /** The reducer for our WordCount job. */
<span class="nc" id="L62">  public static class Reduce extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; {</span>
<span class="nc" id="L63">    private final LongWritable count = new LongWritable();</span>

    @Override
    public void reduce(Text word, Iterable&lt;LongWritable&gt; counts, Context context)
        throws IOException, InterruptedException {
      // Add up the values to get a total number of occurrences of our word.
<span class="nc" id="L69">      count.set(</span>
<span class="nc" id="L70">          StreamSupport.stream(counts.spliterator(), false).mapToLong(LongWritable::get).sum());</span>
<span class="nc" id="L71">      context.write(word, count);</span>
<span class="nc" id="L72">    }</span>
  }

  public static void main(String[] args)
      throws IOException, InterruptedException, ClassNotFoundException {

    // GenericOptionsParser is a utility to parse command line arguments generic to the Hadoop
    // framework. This example won't cover the specifics, but will recognize several standard
    // command line arguments, enabling applications to easily specify a namenode, a
    // ResourceManager, additional configuration resources etc.
<span class="nc" id="L82">    GenericOptionsParser parser = new GenericOptionsParser(args);</span>
<span class="nc" id="L83">    args = parser.getRemainingArgs();</span>

    // Make sure we have the right parameters.
<span class="nc bnc" id="L86" title="All 2 branches missed.">    if (args.length != 3) {</span>
<span class="nc" id="L87">      System.out.println(</span>
          &quot;Usage: hadoop jar bigquery_wordcount.jar [ProjectId] [QualifiedInputTableId] &quot;
              + &quot;[GcsOutputPath]\n&quot;
              + &quot;    ProjectId - Project under which to issue the BigQuery operations. Also &quot;
              + &quot;serves as the default project for table IDs which don't explicitly specify a &quot;
              + &quot;project for the table.\n&quot;
              + &quot;    QualifiedInputTableId - Input table ID of the form &quot;
              + &quot;(Optional ProjectId):[DatasetId].[TableId]\n&quot;
              + &quot;    OutputPath - The output path to write data, e.g. &quot;
              + &quot;gs://bucket/dir/&quot;);
<span class="nc" id="L97">      System.exit(1);</span>
    }

    // Get the individual parameters from the command line.
<span class="nc" id="L101">    String projectId = args[0];</span>
<span class="nc" id="L102">    String inputQualifiedTableId = args[1];</span>
<span class="nc" id="L103">    String outputPath = args[2];</span>

    // Create the job and get its configuration.
<span class="nc" id="L106">    Job job = new Job(parser.getConfiguration(), &quot;wordcount&quot;);</span>
<span class="nc" id="L107">    Configuration conf = job.getConfiguration();</span>

    // Set the job-level projectId.
<span class="nc" id="L110">    conf.set(BigQueryConfiguration.PROJECT_ID_KEY, projectId);</span>

    // Configure input and output.
<span class="nc" id="L113">    BigQueryConfiguration.configureBigQueryInput(conf, inputQualifiedTableId);</span>

    // Set column and predicate filters
<span class="nc" id="L116">    conf.set(BigQueryConfiguration.SELECTED_FIELDS_KEY, &quot;word,word_count&quot;);</span>
<span class="nc" id="L117">    conf.set(BigQueryConfiguration.SQL_FILTER_KEY, &quot;word &gt;= 'A' AND word &lt;= 'zzz'&quot;);</span>
<span class="nc" id="L118">    conf.set(MRJobConfig.NUM_MAPS, &quot;999&quot;);</span>

    // This helps Hadoop identify the Jar which contains the mapper and reducer by specifying a
    // class in that Jar. This is required if the jar is being passed on the command line to Hadoop.
<span class="nc" id="L122">    job.setJarByClass(DirectBigQueryWordCount.class);</span>

    // Tell the job what the output will be.
<span class="nc" id="L125">    job.setOutputKeyClass(Text.class);</span>
<span class="nc" id="L126">    job.setOutputValueClass(LongWritable.class);</span>

<span class="nc" id="L128">    job.setMapperClass(Map.class);</span>
<span class="nc" id="L129">    job.setReducerClass(Reduce.class);</span>

<span class="nc" id="L131">    job.setInputFormatClass(DirectBigQueryInputFormat.class);</span>
<span class="nc" id="L132">    job.setOutputFormatClass(TextOutputFormat.class);</span>

<span class="nc" id="L134">    FileOutputFormat.setOutputPath(job, new Path(outputPath));</span>

<span class="nc" id="L136">    job.waitForCompletion(true);</span>
<span class="nc" id="L137">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.4.201905082037</span></div></body></html>